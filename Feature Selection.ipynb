{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd90feba-4fd0-452a-9509-61931487c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#notebook settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# building a pipeline to preprocess the data\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, learning_curve, validation_curve, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bc6df-e36f-437f-8ed0-f5fb97afa89c",
   "metadata": {},
   "source": [
    "# File Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5425580-2a2b-443f-8d53-952619c483f7",
   "metadata": {},
   "source": [
    "# Paths to feature files\n",
    "train_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/prepared_claims_data_train.csv\"\n",
    "val_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/prepared_claims_data_val.csv\"\n",
    "test_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/prepared_claims_data_test.csv\"\n",
    "\n",
    "# Paths to target files\n",
    "ytrain_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/y_train_encoded.csv\"\n",
    "yval_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/y_val_encoded.csv\"\n",
    "ytest_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/y_test_encoded.csv\"\n",
    "\n",
    "# Load the feature datasets\n",
    "X_train = pd.read_csv(train_path)\n",
    "X_val = pd.read_csv(val_path)\n",
    "X_test = pd.read_csv(test_path)\n",
    "\n",
    "# Load the target datasets\n",
    "y_train = pd.read_csv(ytrain_path)\n",
    "y_val = pd.read_csv(yval_path)\n",
    "y_test = pd.read_csv(ytest_path)\n",
    "\n",
    "# Inspect loaded data\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b11f729-b4f5-485f-97f6-6a2d270fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test with old files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e1f1b1-7010-4c52-a6c3-fa03f595f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (91844, 43) y_train shape: (363063, 2)\n",
      "X_val shape: (91844, 43) y_val shape: (91844, 1)\n",
      "X_test shape: (114806, 43) y_test shape: (114806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/t2s2zdt15tgd3q3dmyd7y88r0000gn/T/ipykernel_39976/3992965449.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  X_test = pd.read_csv(test_path)\n"
     ]
    }
   ],
   "source": [
    "# Paths to feature files\n",
    "train_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/prepared_claims_data_val.csv\"\n",
    "val_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/prepared_claims_data_val.csv\"\n",
    "test_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/prepared_claims_data_test.csv\"\n",
    "\n",
    "# Paths to target files\n",
    "ytrain_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/y_train_encoded.csv\"\n",
    "yval_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/y_val_encoded.csv\"\n",
    "ytest_path = \"/Users/pedrocosta/Desktop/NOVA IMS/Mestrado DSAA/1º Semestre/Apredizagem automática/project_data/testing/y_test_encoded.csv\"\n",
    "\n",
    "# Load the feature datasets\n",
    "X_train = pd.read_csv(train_path)\n",
    "X_val = pd.read_csv(val_path)\n",
    "X_test = pd.read_csv(test_path)\n",
    "\n",
    "# Load the target datasets\n",
    "y_train = pd.read_csv(ytrain_path)\n",
    "y_val = pd.read_csv(yval_path)\n",
    "y_test = pd.read_csv(ytest_path)\n",
    "\n",
    "# Inspect loaded data\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db83a72c-6dc5-492a-9316-4470d1cbcd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Age at Injury', 'Attorney/Representative',\n",
      "       'Average Weekly Wage', 'Carrier Name', 'Carrier Type',\n",
      "       'Claim Identifier', 'County of Injury', 'COVID-19 Indicator',\n",
      "       'District Name', 'Gender', 'Industry Code Description',\n",
      "       'Medical Fee Region', 'WCIO Cause of Injury Description',\n",
      "       'WCIO Nature of Injury Description', 'WCIO Part Of Body Description',\n",
      "       'Zip Code', 'Number of Dependents', 'Cause Injury Category',\n",
      "       'Nature of Injury Category', 'Body Part Category', 'Age_Group',\n",
      "       'Wage_Group', 'Carrier Name Grouped', 'Lag_Time', 'Accident_to_C2_Lag',\n",
      "       'Accident Date_Year', 'Accident Date_Month', 'Assembly Date_Month',\n",
      "       'Assembly Date_Day', 'C-2 Date_Year', 'C-2 Date_Month', 'C-2 Date_Day',\n",
      "       'Accident_Month_Sin', 'Accident_Month_Cos', 'Accident_Day',\n",
      "       'Assembly_Year', 'Assembly_Month_Sin', 'Assembly_Month_Cos',\n",
      "       'Assembly_Day', 'C-2_Month_Sin', 'C-2_Month_Cos', 'C-2_Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda3a0ef-b7b0-455f-a924-2220bb1ebf5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2m/t2s2zdt15tgd3q3dmyd7y88r0000gn/T/ipykernel_39976/1698829476.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "y_train_df = y_train.to_frame()\n",
    "print(y_train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084fbea-0c9b-42f8-823f-5708b62b90ab",
   "metadata": {},
   "source": [
    "# Encodings of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b138224-fad5-4faf-8f7e-1c020f53c616",
   "metadata": {},
   "source": [
    "We decide to encode the variables as follows:\n",
    "- __One-Hot Encoding:__ For variables with a small number of unique values (< 5); preferable because it treats each category independently and avoids introducing an artificial order.\n",
    "- __Label Encoding:__ For variables with a larger number of categories or variables where there is a clear order or hierarchy.\n",
    "- __Ordinal Encoding:__ For variables with a natural order or numeric-like scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067aa5ea-03d3-42eb-b759-a1714a58af24",
   "metadata": {},
   "source": [
    "| **Variable**                     | **Encoding Type**       | **Reason**                                                                 |\n",
    "|----------------------------------|-------------------------|-----------------------------------------------------------------------------|\n",
    "| Age at Injury                    | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Attorney/Representative          | One-Hot                | Binary categorical (Yes/No).                                               |\n",
    "| Average Weekly Wage              | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Carrier Name                     | Label                  | High-cardinality categorical; use Label Encoding.                          |\n",
    "| Carrier Type                     | Label                  | Nominal categorical; Label Encoding is efficient for lower cardinality.    |\n",
    "| Claim Identifier                 | None                   | Unique identifier; leave as-is.                                            |\n",
    "| Claim Injury Type                | Label                  | Multiclass target; Label Encoding is standard for targets.                 |\n",
    "| County of Injury                 | Label                  | High-cardinality categorical; Label Encoding is better for efficiency.     |\n",
    "| COVID-19 Indicator               | One-Hot                | Binary categorical (Yes/No).                                               |\n",
    "| District Name                    | Label                  | Categorical variable, moderate cardinality; Label Encoding is efficient.   |\n",
    "| Gender                           | One-Hot                | Binary categorical (Male/Female/Other).                                    |\n",
    "| Industry Code Description        | Label                  | High-cardinality nominal; Label Encoding is preferred.                     |\n",
    "| Medical Fee Region               | One-Hot                | Nominal categorical (regions); One-Hot avoids unintended ordinal meaning.  |\n",
    "| WCIO Cause of Injury Code        | Label                  | Numerical but nominal; Label Encoding fits better for this use case.       |\n",
    "| WCIO Nature of Injury Code       | Label                  | Numerical but nominal; Label Encoding works best.                          |\n",
    "| WCIO Part Of Body Code           | Label                  | Numerical but nominal; Label Encoding works best.                          |\n",
    "| Zip Code                         | Label                  | High-cardinality categorical; Label Encoding is efficient.                 |\n",
    "| Number of Dependents             | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Lag_Time                         | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Accident_to_C2_Lag               | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Accident Date_Year               | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Accident Date_Month              | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| Accident Date_Day                | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| Assembly Date_Year               | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Assembly Date_Month              | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| Assembly Date_Day                | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| C-2 Date_Year                    | None                   | Numerical variable; leave as-is.                                           |\n",
    "| C-2 Date_Month                   | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| C-2 Date_Day                     | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| Accident_Year                    | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Accident_Month                   | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| Accident_Month_Sin               | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| Accident_Month_Cos               | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| Accident_Day                     | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| Assembly_Year                    | None                   | Numerical variable; leave as-is.                                           |\n",
    "| Assembly_Month                   | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| Assembly_Month_Sin               | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| Assembly_Month_Cos               | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| Assembly_Day                     | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| C-2_Year                         | None                   | Numerical variable; leave as-is.                                           |\n",
    "| C-2_Month                        | One-Hot                | Cyclical data; consider One-Hot or sin/cos transformations.                |\n",
    "| C-2_Month_Sin                    | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| C-2_Month_Cos                    | None                   | Already processed as cyclical; leave as-is.                                |\n",
    "| C-2_Day                          | None                   | Numerical; leave as-is unless specific patterns are found.                 |\n",
    "| Cause Injury Category            | Label                  | Nominal categorical; Label Encoding is efficient.                          |\n",
    "| Nature of Injury Category        | Label                  | Nominal categorical; Label Encoding is efficient.                          |\n",
    "| Body Part Category               | Label                  | Nominal categorical; Label Encoding is efficient.                          |\n",
    "| Age_Group                        | Ordinal                | Categorical with inherent order (e.g., Teen, Adult); Ordinal Encoding fits.|\n",
    "| Wage_Group                       | Ordinal                | Categorical with inherent order (e.g., Low, Medium, High); Ordinal fits.   |\n",
    "| Carrier Name Grouped             | Label                  | High-cardinality nominal; Label Encoding is efficient.                     |\n",
    "| Claim Type Numeric               | None                   | Already encoded as numeric; leave as-is.                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670468b-9ebf-4296-8e11-1242cf49ee72",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24271c-658c-44e1-aea7-4bae8b427b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'Age at Injury', 'Average Weekly Wage', 'Number of Dependents',\n",
    "    'Lag_Time', 'Accident_to_C2_Lag', 'Accident Date_Year', 'Assembly Date_Day',\n",
    "    'C-2 Date_Year', 'C-2 Date_Day', 'Accident_Month_Sin', 'Accident_Month_Cos',\n",
    "    'Accident_Day', 'Assembly_Year', 'Assembly_Month_Sin', 'Assembly_Month_Cos',\n",
    "    'Assembly_Day', 'C-2_Month_Sin', 'C-2_Month_Cos', 'C-2_Day'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82378a7-ca77-4afb-8445-04d6bf9339f2",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3856428-4b4e-4e67-abe4-b212b178b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_features = [\n",
    "    'Attorney/Representative', 'COVID-19 Indicator', 'Gender', \n",
    "    'Medical Fee Region', 'Accident Date_Month', 'Assembly Date_Month', 'C-2 Date_Month'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a07674-3290-4d4e-83f9-66f8e8aa2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb307dbf-22b9-426a-80d1-734fd596c930",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de475d44-3db4-44f4-9917-761993b10df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = [\n",
    "    'Carrier Name', 'Carrier Type', 'District Name', 'Industry Code Description',\n",
    "    'WCIO Cause of Injury Description', 'WCIO Nature of Injury Description',\n",
    "    'WCIO Part Of Body Description', 'Zip Code', 'Cause Injury Category',\n",
    "    'Nature of Injury Category', 'Body Part Category', 'Carrier Name Grouped']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb85a6f-f70e-4203-bbcd-c26c0563fb8f",
   "metadata": {},
   "source": [
    "## Ordinal Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316dc883-9b8b-4441-a38f-cc6dece1d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ordinal features and categories\n",
    "ordinal_features = ['Age_Group', 'Wage_Group']  # Add ordinal features if applicable\n",
    "ordinal_categories = [\n",
    "    ['Teen', 'Young Adult', 'Adult', 'Middle-Aged Adult', 'Older Adult', 'Senior'],  # Age_Group\n",
    "    ['Low', 'Below Average', 'Average', 'Above Average', 'High']  # Wage_Group\n",
    "]\n",
    "\n",
    "# Initialize and fit OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=ordinal_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e0e4d-9d2c-4e5f-8ca7-865fbf6b07e6",
   "metadata": {},
   "source": [
    "# Encoding and Scaling Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bd017-f3af-45f1-93b8-69398ee49bb9",
   "metadata": {},
   "source": [
    "# Define transformations\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "    ('scaler', StandardScaler())  # Optional scaling for one-hot encoded features\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())  # Scale the ordinal features\n",
    "])\n",
    "\n",
    "label_transformer = Pipeline(steps=[\n",
    "    ('label', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())  # Scale the label-encoded features\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "# Combine all transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('onehot', onehot_transformer, onehot_features),\n",
    "    ('ordinal', ordinal_transformer, ordinal_features),\n",
    "    ('label', label_transformer, label_features),\n",
    "    ('num', numerical_transformer, numerical_features)  # Ensure numerical features are also scaled\n",
    "])\n",
    "\n",
    "# Apply the preprocessor: fit on training data and transform all datasets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Retrieve column names dynamically\n",
    "onehot_names = preprocessor.named_transformers_['onehot']['onehot'].get_feature_names_out(onehot_features)\n",
    "ordinal_names = ordinal_features  # Ordinal features retain their original names\n",
    "label_names = label_features      # Label encoded features retain their original names\n",
    "numerical_names = numerical_features\n",
    "\n",
    "# Combine all transformed column names\n",
    "feature_names = np.concatenate([onehot_names, ordinal_names, label_names, numerical_names])\n",
    "\n",
    "# Convert transformed datasets back to DataFrames with column names\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names, index=X_train.index)\n",
    "X_val_transformed = pd.DataFrame(X_val_transformed, columns=feature_names, index=X_val.index)\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "# Save the preprocessor for future use\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Outputs\n",
    "print(\"Validated feature groups:\")\n",
    "print(\"One-hot features:\", onehot_features)\n",
    "print(\"Label features:\", label_features)\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Ordinal features:\", ordinal_features)\n",
    "\n",
    "print(\"Transformed feature names:\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5f8300-5520-4e02-a56a-30c2bd5de38b",
   "metadata": {},
   "source": [
    "### Scalling test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df263c-2820-459a-a90e-ea954e758ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Define transformations\n",
    "# 1. One-Hot Encoding: No scaling for binary variables\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Remove scaling for binary vars\n",
    "])\n",
    "\n",
    "# 2. Ordinal Encoding: Ordinal categories, followed by scaling\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())  # Scale the ordinal features\n",
    "])\n",
    "\n",
    "# 3. Label Encoding: Treat categorical data that can be ordinal (e.g., Low, Medium, High)\n",
    "label_transformer = Pipeline(steps=[\n",
    "    ('label', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    ('scaler', StandardScaler())  # Scale the label-encoded features\n",
    "])\n",
    "\n",
    "# 4. Numerical Features: Apply only scaling\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "# Combine all transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('onehot', onehot_transformer, onehot_features),  # No scaling for one-hot encoded vars\n",
    "    ('ordinal', ordinal_transformer, ordinal_features),\n",
    "    ('label', label_transformer, label_features),\n",
    "    ('num', numerical_transformer, numerical_features)\n",
    "])\n",
    "\n",
    "# Apply the preprocessor: fit on training data and transform all datasets\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Retrieve column names dynamically\n",
    "onehot_names = preprocessor.named_transformers_['onehot']['onehot'].get_feature_names_out(onehot_features)\n",
    "ordinal_names = ordinal_features  # Ordinal features retain their original names\n",
    "label_names = label_features      # Label encoded features retain their original names\n",
    "numerical_names = numerical_features\n",
    "\n",
    "# Combine all transformed column names into a single list\n",
    "feature_names = np.concatenate([onehot_names, ordinal_names, label_names, numerical_names])\n",
    "\n",
    "# Convert transformed datasets back to DataFrames with proper column names and indices\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names, index=X_train.index)\n",
    "X_val_transformed = pd.DataFrame(X_val_transformed, columns=feature_names, index=X_val.index)\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "# Save the preprocessor for future use\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Outputs for validation\n",
    "print(\"\\nFeature Groups:\")\n",
    "print(\"One-hot features:\", onehot_features)\n",
    "print(\"Label features:\", label_features)\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Ordinal features:\", ordinal_features)\n",
    "\n",
    "print(\"\\nTransformed feature names:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Verify the first rows of the transformed data\n",
    "print(\"\\nX_train_transformed:\")\n",
    "print(X_train_transformed.head())\n",
    "\n",
    "print(\"\\nX_val_transformed:\")\n",
    "print(X_val_transformed.head())\n",
    "\n",
    "print(\"\\nX_test_transformed:\")\n",
    "print(X_test_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a31fe6-3835-4c18-8a85-1001650a1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059fa56-3c6a-40a5-b632-8b48807b8990",
   "metadata": {},
   "source": [
    "## Verificaton of the scalling of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba189784-0bfe-444d-a69e-8b83051c9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify scaled data\n",
    "print(\"Scaled X_train mean:\",X_train_transformed.mean(axis=0))\n",
    "print(\"Scaled X_train std:\", X_train_transformed.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c729e-cf45-479d-8ef3-2695de0e06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of features after Scalling\n",
    "num_features2 = X_train_transformed.shape[1]\n",
    "print(f\"Number of features after encoding: {num_features2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e208c-2f9e-4c6b-a8a6-2abe539a9af0",
   "metadata": {},
   "source": [
    "## Verificaton of the mapping of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ad88c-6076-4c79-9848-43d1ab6d427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `y_train`, `y_val`, and `y_test` are Series\n",
    "if isinstance(y_train, pd.DataFrame):\n",
    "    if 'Claim Injury Type' in y_train.columns:  # Replace with actual column name\n",
    "        y_train = y_train['Claim Injury Type']\n",
    "        y_val = y_val['Claim Injury Type']\n",
    "        y_test = y_test['Claim Injury Type']\n",
    "    else:\n",
    "        # If no explicit column name, take the first column\n",
    "        y_train = y_train.iloc[:, 0]\n",
    "        y_val = y_val.iloc[:, 0]\n",
    "        y_test = y_test.iloc[:, 0]\n",
    "\n",
    "# Verify they are Series\n",
    "print(\"y_train type (after extraction):\", type(y_train))\n",
    "print(\"y_val type (after extraction):\", type(y_val))\n",
    "print(\"y_test type (after extraction):\", type(y_test))\n",
    "\n",
    "\n",
    "# Verify the mapping\n",
    "print(\"Mapped y_train unique values:\", y_train.unique())\n",
    "print(\"Mapped y_val unique values:\", y_val.unique())\n",
    "print(\"Mapped y_test unique values:\", y_test.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ee78a-8c2d-40c4-83c1-bfba174a0faa",
   "metadata": {},
   "source": [
    "# Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fb399-595a-4846-b10a-5df537106a20",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f390e75-8e30-431a-90da-efcbb20f1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix= X_train_transformed.corr(method='spearman')\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d3d64-8cf3-41bd-8f8e-e09e3e6306bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap \n",
    "def cor_heatmap(data):\n",
    "    cor_matrix = data.corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(data=cor_matrix, annot=True, cmap= 'YlGnBu' , fmt='.1')\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "cor_heatmap(X_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d57005-2536-47d5-81a4-3b70e1bd4b61",
   "metadata": {},
   "source": [
    "## Identification of High Correlated Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705b444-e25b-4b67-ba8f-0cce8cdf4805",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Step 1: Identify Highly Correlated Pairs and Standalone High Correlations\n",
    "high_corr_pairs = []\n",
    "high_corr_features = set()\n",
    "\n",
    "for col in correlation_matrix.columns:\n",
    "    for row in correlation_matrix.index:\n",
    "        if col != row and abs(correlation_matrix.loc[row, col]) > 0.8:\n",
    "            high_corr_pairs.append((row, col))  # Add pairs to list\n",
    "            high_corr_features.add(row)  # Add features involved in high correlation\n",
    "            high_corr_features.add(col)  # Add features involved in high correlation\n",
    "\n",
    "# Step 2: Identify Binary Variables\n",
    "binary_vars = [col for col in X_train_transformed.columns if X_train_transformed[col].nunique() == 2]\n",
    "\n",
    "# Step 3: Exclude One Variable Per Pair\n",
    "to_exclude = set()\n",
    "\n",
    "# Step 4:Handle high correlation pairs (binary and non-binary)\n",
    "for var1, var2 in high_corr_pairs:\n",
    "    # Retain only one variable for binary pairs\n",
    "    if var1 in binary_vars and var2 in binary_vars:\n",
    "        to_exclude.add(var2)  # Keep one and exclude the other\n",
    "    else:\n",
    "        # For non-binary variables, arbitrarily keep the first variable\n",
    "        to_exclude.add(var2)\n",
    "\n",
    "# Step 5: Add standalone high-correlation features\n",
    "# Exclude any feature in high_corr_features that was not already excluded\n",
    "standalone_high_corr_features = high_corr_features - to_exclude\n",
    "to_exclude.update(standalone_high_corr_features)\n",
    "\n",
    "# Step 6: Create the list of final features\n",
    "final_features = [col for col in X_train_transformed.columns if col not in to_exclude]\n",
    "\n",
    "# Step 7: Improved Print Statements\n",
    "def print_readable(title, items):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"{i}. {item}\")\n",
    "\n",
    "# Print Results\n",
    "print(\"\\nHigh correlation pairs:\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\" - {pair[0]} <--> {pair[1]}\")\n",
    "\n",
    "print_readable(\"Variables with standalone high correlation\", standalone_high_corr_features)\n",
    "print_readable(\"Variables to exclude\", to_exclude)\n",
    "print_readable(\"Remaining variables after exclusion\", final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859eaa1b-ee15-47ba-a272-1e411b3b5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66449f7b-2e87-4d45-a07b-abf6893e8ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ce865-78cf-430b-883d-e864db27a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define essential features\n",
    "essential_features = ['Attorney/Representative_Y', 'Wage_Group','Gender_M','WCIO Cause of Injury Description']\n",
    "\n",
    "# Step 2: Identify Highly Correlated Pairs\n",
    "high_corr_pairs = []\n",
    "for col in correlation_matrix.columns:\n",
    "    for row in correlation_matrix.index:\n",
    "        if col != row and abs(correlation_matrix.loc[row, col]) > 0.8:\n",
    "            high_corr_pairs.append((row, col))\n",
    "\n",
    "# Step 3: Exclude Redundant Features (Skip Essential Features)\n",
    "to_exclude = set()\n",
    "for var1, var2 in high_corr_pairs:\n",
    "    if var1 not in essential_features and var2 not in essential_features:\n",
    "        to_exclude.add(var2)\n",
    "\n",
    "# Step 4: Feature Importance (Random Forest Example)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_transformed, y_train)\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X_train_transformed.columns)\n",
    "\n",
    "# Step 5: Retain Top Features\n",
    "top_features = feature_importances.nlargest(20).index.tolist()\n",
    "\n",
    "# Step 6: Combine Logic for Final Features\n",
    "final_features = [f for f in X_train_transformed.columns if f in top_features and f not in to_exclude]\n",
    "\n",
    "# Step 7: Output Results\n",
    "print(\"\\n--- Final Feature Selection ---\")\n",
    "print(\"High Correlation Pairs:\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\" - {pair[0]} <--> {pair[1]}\")\n",
    "\n",
    "print(\"\\nFeatures to Exclude (High Correlation):\")\n",
    "print(to_exclude)\n",
    "\n",
    "print(\"\\nTop 20 Features (Random Forest):\")\n",
    "print(top_features)\n",
    "\n",
    "print(\"\\nFinal Selected Features:\")\n",
    "for i, feature in enumerate(final_features, 1):\n",
    "    print(f\"{i}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1a5ee-4f69-4ee6-9b8e-73737c0c0917",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94baaa3-e259-4acb-8c49-e4d1af474e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter Features in the Dataset\n",
    "X_train_lasso = X_train_transformed[final_features]\n",
    "X_val_lasso = X_val_transformed[final_features]\n",
    "X_test_lasso = X_test_transformed[final_features]\n",
    "\n",
    "# Train LassoCV\n",
    "lasso = LassoCV(max_iter=5000, cv=5, random_state=42, alphas=np.logspace(-4, 1, 50))\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "\n",
    "\n",
    "# Initialize and fit LassoCV\n",
    "lasso = LassoCV(cv=5, random_state=0)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = lasso.predict(X_val_lasso)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal alpha: {lasso.alpha_}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d39c5-efd9-4ac7-8476-993b649f1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_transformed.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ac3e2-8cea-4e78-beb9-fc75db9a0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=np.logspace(-4, 2, 50), cv=5)\n",
    "ridge.fit(X_train_transformed, y_train)\n",
    "y_pred_ridge = ridge.predict(X_val_transformed)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_val, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_val, y_pred_ridge)\n",
    "\n",
    "print(f\"Optimal alpha (Ridge): {ridge.alpha_}\")\n",
    "print(f\"Ridge Mean Squared Error: {mse_ridge:.4f}\")\n",
    "print(f\"Ridge R^2 Score: {r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1525d-b2e4-493b-baae-7d5fc93ab325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
